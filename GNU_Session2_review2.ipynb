{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junkyuhufs/Practice/blob/main/GNU_Session2_review2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸŒ¿ íŠ¹ê°• 2: ìì—°ì–´ì²˜ë¦¬ì™€ ë””ì§€í„¸ì¸ë¬¸í•™ ë”°ë¼í•˜ê¸°\n",
        "##1. ìì—°ì–¸ì–´ì²˜ë¦¬(NLP) \n",
        "##2. êµ­ì •ì—°ì„¤ í† í”½ëª¨ë¸ë§(Topic-Modeling) \n",
        "##3. ë¬¸í•™ì‘í’ˆ ê°ì„±ë¶„ì„(Sentiment Analysis)\n",
        "##4. ì˜í™”ë¦¬ë·° êµ°ì§‘ë¶„ì„(Clustering Analysis)\n",
        "\n",
        "### ë°œí‘œ: ì´ì¤€ê·œ (í•œêµ­ì™¸êµ­ì–´ëŒ€í•™êµ êµìœ¡ëŒ€í•™ì› ì˜ì–´êµìœ¡ì „ê³µ)"
      ],
      "metadata": {
        "id": "jc0IN0eAkiUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê°œìš”"
      ],
      "metadata": {
        "id": "BDwtugcFWClP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-eitBRrkhgJ"
      },
      "outputs": [],
      "source": [
        "#@markdown Introduction \n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [\"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.01.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.02.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.03.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.04.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.05.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.06.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 7)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Python ì‹œì‘í•˜ê¸°\n",
        "##í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì˜ˆì‹œ (Preprocessing examples)"
      ],
      "metadata": {
        "id": "TxTvBlncmnkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Python library & ì „ì²˜ë¦¬\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [ \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.07.png\",\n",
        "         \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.08.png\",\n",
        "         \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.11.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 4)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JLYBUfV1rCQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Import/Install relevant packages\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zk3mv9Tdmult"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \"The rain in Spain falls mainly on the plain.\" ì „ì²˜ë¦¬\n",
        "text = \"The rain in Spain falls mainly on the plain.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.is_stop)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
        "rows = []\n",
        "\n",
        "for t in doc:\n",
        "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=cols)\n",
        "    \n",
        "df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Du694UkntK21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sentence ì‹œê°í™”\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "id": "vckRAgRZteiP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1] Topic modeling w/ ë¯¸êµ­ ëŒ€í†µë ¹ ì—°ì„¤ë¬¸"
      ],
      "metadata": {
        "id": "id1w71eot1S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ì ì¬ ë””ë¦¬í´ë ˆ í• ë‹¹(Latent Dirichlet Allocation, LDA)\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [ \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.09.png\",\n",
        "         \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.10.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 3)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8I-mqeH_mWWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í•„ìš”í•œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° \n",
        "\n",
        "* ë°ì´í„°: **state-of-the-union.csv:** 1970ì—ì„œ 2012ê¹Œì§€ ë¯¸êµ­ ëŒ€í†µë ¹ êµ­ì •ì—°ì„¤"
      ],
      "metadata": {
        "id": "I_eTrbnruQJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ğŸ’¾ Topic modeling ì‹¤ìŠµíŒŒì¼ ë‹¤ìš´ë°›ê¸°](https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/text-analysis/data/state-of-the-union.csv)"
      ],
      "metadata": {
        "id": "QJOIZHBpuRnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown êµ­ì •ì—°ì„¤ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Make data directory if it doesn't exist\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Download the CSV file\n",
        "url = \"https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/text-analysis/data/state-of-the-union.csv\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the content to a file\n",
        "with open(\"data/state-of-the-union.csv\", \"wb\") as f:\n",
        "    f.write(response.content)\n"
      ],
      "metadata": {
        "id": "66y8Ig6XBu8H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ë¶ˆëŸ¬ì˜¨ csvë¥¼ data frame í˜•íƒœë¡œ ë³€í™˜ ë° ì²­ì†Œ\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"data/state-of-the-union.csv\")\n",
        "# Clean it up a little bit, removing non-word characters (numbers and ___ etc)\n",
        "df.content = df.content.str.replace(\"[^A-Za-z ]\", \" \")\n",
        "df.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DfQCZFFuu3fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”\n",
        "# Import the wordcloud library\n",
        "from wordcloud import WordCloud\n",
        "# Join the different processed titles together.\n",
        "long_string = ','.join(list(df.content.values))\n",
        "# Create a WordCloud object\n",
        "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=36, contour_color='steelblue', width = 600, height=400)\n",
        "# Generate a word cloud\n",
        "wordcloud.generate(long_string)\n",
        "# Visualize the word cloud\n",
        "wordcloud.to_image()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "In-xOrwHvSzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA (ì ì¬ ë””ë¦¬í´ë ˆ í• ë‹¹)ì„ ìœ„í•œ ìë£Œ ì¤€ë¹„\n",
        "\n",
        "+ gensim.utils.simple_preprocessë¥¼ ì´ìš©í•˜ì—¬, documentë¥¼ a list of tokensìœ¼ë¡œ ë³€í™˜. \n",
        "+ ì†Œë¬¸ìë¡œ ë°”ê¾¸ê¸°, í† í°í™” ë“± (ì„ íƒì‚¬í•­) "
      ],
      "metadata": {
        "id": "2JJhthA8NNq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Gensimì„¤ì¹˜\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install gensim"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5lFhdJTd3Mf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown gensimì˜ simple_preprocess ì´ìš©í•œ í† í°í™”\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "df.content = df.content.apply(simple_preprocess)"
      ],
      "metadata": {
        "id": "uYBrLYqRNXuX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¶ˆìš©ì–´(stopwords) ì œê±°í•˜ê¸°: ì˜ˆ) to, I, the, a, from, ë“±ë“±"
      ],
      "metadata": {
        "id": "brll8tdLZzLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown stopwords ì œê±°\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# stop_words.extend(['from', 'to']) # add more if want\n",
        "df.content = df.content.apply(lambda words: [word for word in words if word not in stop_words])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KKVX4GPQN66Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown í† í°í™” > ì¹´ìš´íŠ¸ë²¡í„° (BOWí˜•íƒœë¡œ ë³€í™˜) í˜•íƒœì¸ corpus ìƒì„±; ì²˜ìŒ 20ê°œ ê²°ê³¼ í™•ì¸\n",
        "texts = df.content #Gensimì—ì„œëŠ” í† í°í™”ëœ ê²°ê³¼ë¥¼ textsë¡œ ì§€ì •í•´ì•¼ í•¨\n",
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5) #ì¶œí˜„í•œ ë¬¸ì„œ ë¹ˆë„ìˆ˜ê°€ ë‚®ê±°ë‚˜ (ë¬¸ì„œì—ì„œ 5ë²ˆ ì´í•˜) or ë†’ì€ ë‹¨ì–´ë“¤ (0.5 -> 50%ì´ìƒ) ì œì™¸ \n",
        "corpus = [dictionary.doc2bow(text) for text in texts] #doc2bow() >> í† í°í™”ëœ ê²°ê³¼ë¥¼ ì¹´ìš´íŠ¸ ë²¡í„°, ì¦‰ BOWí˜•íƒœë¡œ ë³€í™˜; Gensimì—ì„œëŠ” doc2bow()ì˜ ê²°ê³¼ë¥¼ corpusë¡œ ì§€ì •í•´ì•¼ í•¨\n",
        "corpus[0][:20]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h_K6oUFUOSTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ì¹´ìš´íŠ¸ ë²¡í„°í˜•íƒœì˜ corpusë¥¼ TF-IDFë¡œ ë³€í™˜; ì²˜ìŒ 20ê°œ ê²°ê³¼ í™•ì¸\n",
        "from gensim import models\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "corpus_tfidf = tfidf[corpus]\n",
        "corpus_tfidf[0][-20:]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oP-YqoxoO5cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown LDA(ì ì¬ ë””ë¦¬í´ë ˆí• ë‹¹) ì‹¤í–‰; í† í”½ìˆ˜ = 15ê°œ ì§€ì • (3ê°œë§Œ í™•ì¸)\n",
        "from gensim import models\n",
        "n_topics = 15\n",
        "lda_model = models.ldamodel.LdaModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=n_topics)\n",
        "\n",
        "#15ê°œ ì¤‘ 3ê°œë§Œ ë³´ì—¬ì£¼ê¸°\n",
        "lda_model.print_topics()[:3]"
      ],
      "metadata": {
        "id": "2LMATQYyPjTD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "%%capture\n",
        "!pip install pyLDAvis\n",
        "!pip install \"pandas<2.0.0\" "
      ],
      "metadata": {
        "cellView": "form",
        "id": "cx6QDKaybUQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA ì‹œê°í™”"
      ],
      "metadata": {
        "id": "Ic7ap7JPb7Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown LDAê²°ê³¼ ì‹œê°í™”\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j1XyigaVQEZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Sentiment Analysis (w/ Harry Potter)"
      ],
      "metadata": {
        "id": "usEAgkWkRPBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intro to SA\n",
        "\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [\"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.13.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.12.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.14.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 4)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RNuA9SEtRTft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë¶„ì„í•  ìë£Œ ì¤€ë¹„"
      ],
      "metadata": {
        "id": "OxA50awOT-Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ [ì†ŒìŠ¤ë§í¬: Harry Potter ìë£Œë¥¼ ê³µìœ í•œ ê¹ƒí—ˆë¸Œ ì‚¬ì´íŠ¸](https://github.com/ErikaJacobs/Harry-Potter-Text-Mining.git)\n",
        "\n",
        "+ [í…ìŠ¤íŠ¸ ì˜ˆì‹œ](https://raw.githubusercontent.com/ErikaJacobs/Harry-Potter-Text-Mining/master/Book%20Text/HPBook1.txt)"
      ],
      "metadata": {
        "id": "6zTPhIAnRgx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Harry Potterìë£Œ ê°€ì ¸ì˜¤ê¸°\n",
        "!git clone https://github.com/ErikaJacobs/Harry-Potter-Text-Mining.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jzAN3jZORiE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ë°ì´í„° ì „ì²˜ë¦¬: Pandasì´ìš© ë°ì´í„° ì •ë¦¬ (ì±…ì˜ í•œ ì±•í„°ê°€ í•œ ì…€ì— ìˆëŠ” ìƒíƒœ)\n",
        "import pandas as pd #Importing Pandas package\n",
        "%cd /content/Harry-Potter-Text-Mining/Book Text\n",
        "\n",
        "import glob \n",
        "fns = glob.glob('*.txt')\n",
        "df = pd.DataFrame()\n",
        "for fn in fns:\n",
        "  dftmp = pd.read_csv(fn, sep=\"@\")\n",
        "  df = pd.concat([df, dftmp])\n",
        "\n",
        "%cd /content\n",
        "\n",
        "df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Wd11Hx9_R0EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ë°ì´í„° ì „ì²˜ë¦¬ ë¶ˆìš©ì–´(stopwords) ì œê±°\n",
        "import nltk #Import NLTK library\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') #installed punkt to fix error\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords #Import stopwords to Python\n",
        "\n",
        "stopwords = set(stopwords.words('english')) #English stopwords assigned to \"stopwords\" object\n",
        "\n",
        "import string #Punctuation\n",
        "\n",
        "# Function for removing punctuation\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text\n",
        "\n",
        "stopwords = [''.join(item for item in x if item not in string.punctuation) for x in stopwords] #Remove punctuation from stopwords\n",
        "\n",
        "df['WordCountText']=df['Text'].str.lower().apply(remove_punctuations).apply(word_tokenize) # Word Count Text\n",
        "# Word Count\n",
        "df['WordCloudText']=df['WordCountText'].apply(lambda x: [word for word in x if word not in stopwords]) # Word Cloud Text\n",
        "df['WordCount'] = df['WordCountText'].str.len() #Word Count Per Chapter"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gOMavAe8SOyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ë°ì´í„° ì „ì²˜ë¦¬: ì±… > ë¬¸ì¥ë‹¨ìœ„ë¡œ (ì±•í„°ê°€ ë¬¸ì¥ë‹¨ìœ„ë¡œ ë‚˜ë‰œ ìƒíƒœ)\n",
        "# Creating a table breaking down the text by each sentence, rather than each chapter.\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Make smaller table - reset index to prepare for further work\n",
        "dfsentiment = df[['Book','Chapter','Text']].reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "dfsentiment = dfsentiment.join(dfsentiment.Text.apply(sent_tokenize).rename('Sentences')) # Breaking apart text into sentences\n",
        "\n",
        "#Put every tokenized sentence into its own row\n",
        "dfsentiment2 = dfsentiment.Sentences.apply(pd.Series) \\\n",
        "    .merge(dfsentiment, left_index = True, right_index = True) \\\n",
        "    .drop([\"Text\"], axis = 1) \\\n",
        "    .drop([\"Sentences\"], axis = 1) \\\n",
        "    .melt(id_vars = ['Book', 'Chapter'], value_name = \"Sentence\") \\\n",
        "    .drop(\"variable\", axis = 1) \\\n",
        "    .dropna()\n",
        "\n",
        "# Sort new table by Book and Chapter - reset index to reflect new order\n",
        "dfsentiment2=dfsentiment2.sort_values(by=['Book', 'Chapter']) \\\n",
        "    .reset_index() \\\n",
        "    .drop(['index'], axis = 1)\n",
        "\n",
        "# Clean punctuation, lower case\n",
        "dfsentiment2['Sentence']=dfsentiment2.Sentence.apply(remove_punctuations).apply(lambda x: x.lower()) \\\n",
        "\n",
        "# Check first five values\n",
        "dfsentiment2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zcC4zJ9JSkso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ê°ì •ë¶„ì„ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "T-ATz9QaUDfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(VADER library) ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "sid=nltk.sentiment.vader.SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hF38sFIGUHdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Harry Potter ì˜ˆì‹œë¬¸ì¥ (stemmed ë¬¸ì¥)\n",
        "\n",
        "\n",
        "|ì¶œì²˜ | ì˜ˆì‹œë¬¸ì¥ | ê°ì • |\n",
        "|--|--|--|\n",
        "|[0,1,1]|'the boy who lived mr and mrs dursley of number four privet drive were **proud** to say that they were perfectly normal **thank** you very much'|ğŸ˜„ Positive|[0,1,1]|\n",
        "|[1,1,1]|'they were the last people youd expect to be involved in anything **strange** or **mysterious** because they just didnt hold with such **nonsense**'|ğŸ˜¡ Negative |\n",
        "|[2,1,1]|'mr dursley was the director of a firm called grunnings which made drills'|ğŸ˜ Neutral|\n",
        "\n",
        "\n",
        "+ *Note*. ì¶œì²˜ == [sentence number, Book, Chapter]"
      ],
      "metadata": {
        "id": "Do0r7a0tFiLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ë¬¸ì¥ë³„ë¡œ ê°ì •ë¶„ì„ ì ìˆ˜ ë¶€ì—¬; Compound, positive, negative, neutral \n",
        "# Get intensity scores of each sentence\n",
        "dfsentiment2['Score']=dfsentiment2.Sentence.apply(lambda x: sid.polarity_scores(x))\n",
        "\n",
        "# Place scores in own columns\n",
        "dfsentiment2['CompScore']=dfsentiment2.Score.apply(lambda x: x.get(\"compound\"))\n",
        "dfsentiment2['PosScore']=dfsentiment2.Score.apply(lambda x: x.get(\"pos\"))\n",
        "dfsentiment2['NegScore']=dfsentiment2.Score.apply(lambda x: x.get(\"neg\"))\n",
        "dfsentiment2['NeuScore']=dfsentiment2.Score.apply(lambda x: x.get(\"neu\"))\n",
        "\n",
        "# With scores extracted, the original score field can be removed\n",
        "dfsentiment2 = dfsentiment2.drop([\"Score\"], axis=1)\n",
        "\n",
        "# Adding Sentiment Flags\n",
        "dfsentiment2['PosFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x >= 0.05 else 0)\n",
        "dfsentiment2['NegFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x <= -0.05 else 0)\n",
        "dfsentiment2['NeuFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x < 0.05 and x > -0.05 else 0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9wIjPpC3Uj6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfsentiment2.head(20)"
      ],
      "metadata": {
        "id": "QHL5QRuwU_f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown [1] ê°ì •ë¶„ì„ ê²°ê³¼ ë§‰ëŒ€ê·¸ë˜í”„ (ë¶€ì •, ì¤‘ë¦½, ê¸ì •)\n",
        "\n",
        "print('* Negative Flag: ', dfsentiment2['NegFlag'].sum())\n",
        "print('* Neutral Flag: ', dfsentiment2['NeuFlag'].sum())\n",
        "print('* Positive Flag: ', dfsentiment2['PosFlag'].sum())\n",
        "print(\"=\"*50)\n",
        "print('Total: ',dfsentiment2['PosFlag'].sum()+dfsentiment2['NeuFlag'].sum()+dfsentiment2['NegFlag'].sum())\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Negative = int(dfsentiment2['NegFlag'].sum())\n",
        "Neutral = int(dfsentiment2['NeuFlag'].sum())\n",
        "Positive = int(dfsentiment2['PosFlag'].sum())\n",
        "\n",
        "# Your three integer frequencies\n",
        "freqs = [Negative, Neutral, Positive]\n",
        "# freqs = [18385, 33544, 19055]\n",
        "\n",
        "# Create labels for the bars\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "# Create x coordinates for the bars\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Generate the bar plot\n",
        "plt.bar(x, freqs)\n",
        "\n",
        "\n",
        "# Specify the colors for each category\n",
        "colors = ['lightblue', 'gray', 'orange']\n",
        "\n",
        "# Generate the bar plot with custom colors\n",
        "\n",
        "bars = plt.bar(x, freqs, color=colors)\n",
        "# Add labels to the x-axis\n",
        "plt.xticks(x, labels)\n",
        "\n",
        "# Set axis labels\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Set a title for the plot\n",
        "plt.title('Bar plot of Sentiment categories')\n",
        "plt.ylim(0, 40000) \n",
        "# Add the frequency text within each bar\n",
        "for bar, freq in zip(bars, freqs):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 2, str(freq),\n",
        "             ha='center', va='bottom', fontsize=12, color='gray')\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TII9dv7EkLwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown [2] ê°ì •ë¶„ì„ ì¹´í…Œê³ ë¦¬ íŒŒì´ì°¨íŠ¸ (ë¹„ìœ¨í™•ì¸ìš©)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Negative = int(dfsentiment2['NegFlag'].sum())\n",
        "Neutral = int(dfsentiment2['NeuFlag'].sum())\n",
        "Positive = int(dfsentiment2['PosFlag'].sum())\n",
        "\n",
        "# Your three integer frequencies\n",
        "freqs = [Negative, Neutral, Positive]\n",
        "\n",
        "# Create labels for the segments\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "# Specify the colors for each segment\n",
        "colors = ['lightblue', 'gray', 'orange']\n",
        "\n",
        "# Generate the pie chart with custom colors\n",
        "plt.pie(freqs, labels=labels, colors=colors, autopct='%.1f%%', startangle=90)\n",
        "\n",
        "# Set a title for the plot\n",
        "plt.title('Pie chart of Sentiment categories')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N7iyPZVEnAFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ì‹œê³„ì—´ ë¶„ì„ ì‹œê°í™”"
      ],
      "metadata": {
        "id": "nz5KP9vxV5m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 7ê¶Œ ê°œë³„ì ìœ¼ë¡œ ê°ì •ë³€í™” íë¦„ í™•ì¸\n",
        "#Time series of sentiments in 7 books of Harry Potter\n",
        "\n",
        "dfsentiment2.groupby('Book').mean()['CompScore']\n",
        "\n",
        "def Titles(x):\n",
        "    if x == 1:\n",
        "        return \"1 - Sorcerer's Stone\"\n",
        "    if x == 2:\n",
        "        return \"2 - Chamber of Secrets\"\n",
        "    if x == 3:\n",
        "        return \"3 - Prizoner of Azkaban\"\n",
        "    if x == 4:\n",
        "        return \"4 - Goblet of Fire\"\n",
        "    if x == 5:\n",
        "        return \"5 - Order of the Phoenix\"\n",
        "    if x == 6:\n",
        "        return \"6 - Half Blood Prince\"\n",
        "    if x == 7:\n",
        "        return \"7 - Deathly Hallows\"\n",
        "\n",
        "dfsentiment2['BookTitle']=dfsentiment2.Book.apply(lambda x: Titles(x))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "colorsList = ['#DC8458', '#950702', '#8E067D', '#2E8C44', '#395196', '#60A619','#ECA10A'] #Mauraders Map Colors\n",
        "ColorMap = matplotlib.colors.ListedColormap(colorsList)\n",
        "\n",
        "# plot data\n",
        "fig, ax = plt.subplots(figsize=(10,16))\n",
        "# use unstack()\n",
        "dfsentiment2.groupby(['Chapter','BookTitle']).mean()['CompScore'].unstack().plot(ax=ax, subplots=True, ylim=(-0.25, 0.25), colormap=ColorMap)\n",
        "plt.style.use('ggplot')\n",
        "ax.set_ylabel('Compound Sentiment Score')\n",
        "\n",
        "[ax.legend(loc=1) for ax in plt.gcf().axes]"
      ],
      "metadata": {
        "id": "pcdnCk0cWACI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 7ê¶Œì„ í†µí•©í•˜ì—¬ ê°ì •ë³€í™” íë¦„ í™•ì¸\n",
        "#Time series of sentiments in 7 books of Harry Potter\n",
        "\n",
        "dfsentiment2.groupby('Book').mean()['CompScore']\n",
        "\n",
        "def Titles(x):\n",
        "    if x == 1:\n",
        "        return \"1 - Sorcerer's Stone\"\n",
        "    if x == 2:\n",
        "        return \"2 - Chamber of Secrets\"\n",
        "    if x == 3:\n",
        "        return \"3 - Prizoner of Azkaban\"\n",
        "    if x == 4:\n",
        "        return \"4 - Goblet of Fire\"\n",
        "    if x == 5:\n",
        "        return \"5 - Order of the Phoenix\"\n",
        "    if x == 6:\n",
        "        return \"6 - Half Blood Prince\"\n",
        "    if x == 7:\n",
        "        return \"7 - Deathly Hallows\"\n",
        "\n",
        "dfsentiment2['BookTitle']=dfsentiment2.Book.apply(lambda x: Titles(x))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "colorsList = ['#DC8458', '#950702', '#8E067D', '#2E8C44', '#395196', '#60A619','#ECA10A'] #Mauraders Map Colors\n",
        "ColorMap = matplotlib.colors.ListedColormap(colorsList)\n",
        "\n",
        "# plot data\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "# use unstack()\n",
        "dfsentiment2.groupby(['Chapter','BookTitle']).mean()['CompScore'].unstack().plot(ax=ax, subplots=False, ylim=(-0.3, 0.3), colormap=ColorMap)\n",
        "plt.style.use('ggplot')\n",
        "ax.set_ylabel('Compound Sentiment Score')\n",
        "\n",
        "[ax.legend(loc=2) for ax in plt.gcf().axes]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "urdwcB2diXL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT says:** In Harry Potter and the Deathly Hallows, the main tragic event between chapters 25 and 28 is the aftermath of Dobby's death. Dobby, the house-elf, dies a hero while saving Harry and his friends from the Death Eaters at Malfoy Manor.\n",
        "\n",
        "\n",
        "+ The main tragic event that occurs between chapters 25 and 28 in Harry Potter and the Deathly Hallows (Book 7) is the death of Dobby, the house-elf. This event takes place in Chapter 23, \"Malfoy Manor\", and is not directly within the range you mentioned (chapters 25-28). However, its consequences and emotional impact on the characters continue to resonate in the following chapters.\n",
        "\n",
        "+ Dobby dies while helping Harry, Hermione, Ron, Luna, Dean, and Griphook escape from Malfoy Manor, where they were captured and held prisoner by Bellatrix Lestrange and other Death Eaters. In an attempt to rescue them, Dobby Apparates into the Manor, and in the ensuing chaos, he is fatally struck by a knife thrown by Bellatrix Lestrange as they Disapparate away.\n",
        "\n",
        "+ Dobby's death is a significant and heartbreaking moment in the story, as he dies a hero, saving Harry and his friends from the Death Eaters. It underscores the themes of loyalty, sacrifice, and the importance of valuing all beings, regardless of their background or status."
      ],
      "metadata": {
        "id": "y7Kw52z_h7DX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT says:**\n",
        "\n",
        "**Ending story:** The ending of Harry Potter and the Deathly Hallows (Book 7) sees the final defeat of Lord Voldemort by Harry Potter during the Battle of Hogwarts. The ending is generally considered happy, as it brings the closure of the long-standing conflict between Harry and Voldemort, and most of the central characters, including Harry, Ron, and Hermione, survive and go on to live fulfilling lives. The book concludes with an epilogue set 19 years later, where Harry, Ron, Hermione, and their families are shown sending their own children off to Hogwarts School of Witchcraft and Wizardry, signifying a hopeful and peaceful future."
      ],
      "metadata": {
        "id": "21XMBehblCJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[3] Cluster analysis w/ movie reviews"
      ],
      "metadata": {
        "id": "5PeqhNiQX2F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown CA intro\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [\"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.20.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.21.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.22.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 4)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4GDHpqLlX6Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Import/Install relevant packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "from sklearn import feature_extraction\n",
        "!pip install mpld3\n",
        "import mpld3\n",
        "import requests"
      ],
      "metadata": {
        "cellView": "form",
        "id": "krYuonNxYGQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì˜í™” ë¦¬ë·° ìë£Œ ì¤€ë¹„í•˜ê¸° (ì˜¨ë¼ì¸ ìë£Œ ë¶ˆëŸ¬ì˜´)\n",
        "\n",
        "+ [titles](https://raw.githubusercontent.com/brandomr/document_cluster/master/title_list.txt)\n",
        "+ [genres](https://raw.githubusercontent.com/brandomr/document_cluster/master/genres_list.txt)\n",
        "+ [synopses(wiki)](https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_wiki.txt)\n",
        "+ [synopses(imdb)](https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_imdb.txt)"
      ],
      "metadata": {
        "id": "viUftP9bYoKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 1ë‹¨ê³„ ì²˜ë¦¬: ì‚¬ì´íŠ¸ì—ì„œ ìƒìœ„ 100ê°œì˜ ìë£Œë¥¼ ê°ê° ê°€ì ¸ì˜¤ê¸°\n",
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/title_list.txt\"\n",
        "titles = requests.get(url).text.split('\\n')\n",
        "titles = titles[:100]\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/genres_list.txt\"\n",
        "genres = requests.get(url).text.split('\\n')\n",
        "genres = genres[:100]\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_wiki.txt\"\n",
        "synopses_wiki = requests.get(url).text.split('\\n BREAKS HERE')\n",
        "synopses_wiki = synopses_wiki[:100]\n",
        "# cleaning\n",
        "synopses_clean_wiki = []\n",
        "for text in synopses_wiki:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    #strips html formatting and converts to unicode\n",
        "    synopses_clean_wiki.append(text)\n",
        "synopses_wiki = synopses_clean_wiki\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_imdb.txt\"\n",
        "synopses_imdb = requests.get(url).text.split('\\n BREAKS HERE')\n",
        "synopses_imdb = synopses_imdb[:100]\n",
        "# cleaning\n",
        "synopses_clean_imdb = []\n",
        "for text in synopses_imdb:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    #strips html formatting and converts to unicode\n",
        "    synopses_clean_imdb.append(text)\n",
        "synopses_imdb = synopses_clean_imdb\n",
        "\n",
        "#@markdown 2ë‹¨ê³„ì²˜ë¦¬: wikiì™€ imdbì˜ synopsis í•©ì¹˜ê¸°\n",
        "synopses = []\n",
        "for i in range(len(synopses_wiki)):\n",
        "    item = synopses_wiki[i] + synopses_imdb[i]\n",
        "    synopses.append(item)\n",
        "synopses[0]\n",
        "\n",
        "#@markdown 3ë‹¨ê³„ ì²˜ë¦¬: ì˜í™”ìˆœìœ„ ì €ì¥\n",
        "# generates index for each item in the corpora (in this case it's just rank) and I'll use this for scoring later\n",
        "ranks = []\n",
        "for i in range(0,len(titles)):\n",
        "    ranks.append(i)\n",
        "\n",
        "\n",
        "#@markdown 4ë‹¨ê³„ ì²˜ë¦¬: ì˜í™”ì œëª©, ì¤„ê±°ë¦¬, ì¥ë¥´, ìˆœìœ„ê°€ ëª‡ ê°œì”© ë“¤ì–´ì™”ëŠ”ì§€ í™•ì¸\n",
        "print(\"=\"*50)\n",
        "print(\"ìë£Œìš”ì•½\")\n",
        "print(\"=\"*50)\n",
        "print(str(len(titles)) + ' titles')\n",
        "print(str(len(synopses)) + ' synopses')\n",
        "print(str(len(genres)) + ' genres')\n",
        "print(str(len(ranks)) + ' ranks')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sydRxvLIZBrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##data cleaning"
      ],
      "metadata": {
        "id": "KRGSxB0aa4u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 1ë‹¨ê³„: NLTKì—ì„œ stopwordsì™€ stemmer ê°€ì ¸ì˜¤ê¸°\n",
        "# load nltk's English stopwords as variable called 'stopwords'\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#@markdown 2ë‹¨ê³„: tokenize with stemmingìœ„í•œ í•¨ìˆ˜ ë§Œë“¤ê¸°\n",
        "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
        "def tokenize_and_stem(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems\n",
        "\n",
        "def tokenize_only(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J0OmNHgEa9RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Stemmingí•œ í•¨ìˆ˜ì ìš©í•˜ì—¬ ë‹¨ì–´ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° í™•ì¸\n",
        "nltk.download('punkt')\n",
        "totalvocab_stemmed = []\n",
        "totalvocab_tokenized = []\n",
        "for i in synopses:\n",
        "    allwords_stemmed = tokenize_and_stem(i)\n",
        "    totalvocab_stemmed.extend(allwords_stemmed)\n",
        "    \n",
        "    allwords_tokenized = tokenize_only(i)\n",
        "    totalvocab_tokenized.extend(allwords_tokenized)\n",
        "\n",
        "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
        "vocab_frame"
      ],
      "metadata": {
        "id": "CqtBqdHXb3IN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means clustering"
      ],
      "metadata": {
        "id": "oogVU0uuf9Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown â–¶ï¸ TF-IDFì´ìš© ë²¡í„°ë¡œ ë³€í™˜; ë¹ˆë„ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ì€ ê²ƒì€ ë°°ì œ\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
        "                                 min_df=0.2, stop_words='english',\n",
        "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(synopses)\n",
        "\n",
        "#@markdown â–¶ï¸ TF-IDFì— ì´ìš©ëœ ë‹¨ì–´ë¦¬ìŠ¤íŠ¸ í™•ì¸ (312302ë‹¨ì–´ > 563ë‹¨ì–´)\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "print(terms)\n",
        "print(tfidf_matrix.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0NPtUctyf0L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown â–¶ï¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚° (100ê°œì˜ ë¬´ë¹„ë¦¬ë·°ê°€ 563ì°¨ì›ì—ì„œ ê°ê° í•œ ì ìœ¼ë¡œ í‘œí˜„ê°€ëŠ¥; ì ë“¤ ê°„ì˜ ê±°ë¦¬ê³„ì‚°)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "dist = 1 - cosine_similarity(tfidf_matrix)\n",
        "\n",
        "print(\"ìë£Œ ê²°ê³¼ í¬ê¸°:\", dist.shape)\n",
        "print(\"=\"*50)\n",
        "dist"
      ],
      "metadata": {
        "cellView": "form",
        "id": "peiBTY-hqKZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown êµ°ì§‘ì„ 5ê°œë¡œ ì •í•˜ì—¬ êµ°ì§‘ë¶„ì„\n",
        "from sklearn.cluster import KMeans\n",
        "num_clusters = 5\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(tfidf_matrix)\n",
        "clusters = km.labels_.tolist()\n",
        "# clusters\n",
        "\n",
        "import pandas as pd\n",
        "films = { 'title': titles, 'rank': ranks, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
        "frame = pd.DataFrame(films, index = [clusters] , columns = ['rank', 'title', 'cluster', 'genre'])\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"1. êµ°ì§‘ë³„ë³„ë¡œ ë¬¶ì¸ ì˜í™”ìˆ˜\")\n",
        "print(\"=\"*50)\n",
        "print(frame['cluster'].value_counts())\n",
        "print(\"=\"*50)\n",
        "print(\"2. êµ°ì§‘ë³„ ìˆœìœ„(Rank) í‰ê· \")\n",
        "print(\"=\"*50)\n",
        "grouped = frame['rank'].groupby(frame['cluster'])\n",
        "print(grouped.mean())\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"3. ë¶„ë¥˜ ê²°ê³¼ ë³´ê¸°\")\n",
        "print(\"=\"*50)\n",
        "frame\n"
      ],
      "metadata": {
        "id": "98QtRNy7jfxX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ê° êµ°ì§‘ë³„ ì£¼ìš”ë‹¨ì–´ì™€ ì˜í™”ëª©ë¡ í™•ì¸\n",
        "print(\"Top terms per cluster:\")\n",
        "print()\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "for i in range(num_clusters):\n",
        "    print(\"Cluster %d words:\" % i, end='')\n",
        "    for ind in order_centroids[i, :6]:\n",
        "        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Cluster %d titles:\" % i, end='')\n",
        "    for title in frame.loc[i]['title'].values.tolist():\n",
        "        print(' %s,' % title, end='')\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lTXZUaGrkGKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown êµ°ì§‘ë³„ í‚¤ì›Œë“œë¥¼ ì´ìš©í•˜ì—¬, êµ°ì§‘ë³„ ì´ë¯¸ì§€ë¥¼ AIë¡œ ê·¸ë¦¼ (Midjourney ì´ìš©)\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [\"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.15.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.16.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.17.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.18.png\",\n",
        "        \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.19.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 6)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "id": "JkaXTkehtRr_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multidimensional scaling (ì‹œê°í™”ë¥¼ ìœ„í•œ ì°¨ì› ì¶•ì†Œ 563 -> 2)"
      ],
      "metadata": {
        "id": "lH_TQB26k-aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ê´€ë ¨ packageë¶ˆëŸ¬ì˜¨ í›„ MDSì‹¤í–‰\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
        "xs, ys = pos[:, 0], pos[:, 1]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rsVjrXcVk_SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown êµ°ì§‘ì˜ ìƒ‰ê¹”ê³¼ ì´ë¦„ ì§€ì •\n",
        "#set up colors per clusters using a dict\n",
        "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
        "\n",
        "#set up cluster names using a dict\n",
        "cluster_names = {0: 'Family, home, war', \n",
        "                 1: 'Police, killed, murders', \n",
        "                 2: 'Father, New York, brothers', \n",
        "                 3: 'Dance, singing, love', \n",
        "                 4: 'Killed, soldiers, captain'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "72PfJbFFlbY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown MDSì‹œê°í™”\n",
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "#group by cluster\n",
        "groups = df.groupby('label')\n",
        "\n",
        "# set up plot\n",
        "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
        "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "for name, group in groups:\n",
        "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
        "    ax.set_aspect('auto')\n",
        "    ax.tick_params(\\\n",
        "        axis= 'x',          # changes apply to the x-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        bottom='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelbottom='off')\n",
        "    ax.tick_params(\\\n",
        "        axis= 'y',         # changes apply to the y-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        left='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelleft='off')\n",
        "    \n",
        "ax.legend(numpoints=1)  #show legend with only 1 point\n",
        "\n",
        "#add label in x,y position with the label as the film title\n",
        "for i in range(len(df)):\n",
        "    ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['title'], size=8)\n",
        "    \n",
        "plt.show() #show the plot"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NFHB9RrMlsdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hierarchical document clustering(dendrogram)"
      ],
      "metadata": {
        "id": "7TZ7VFAEl7Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Dendrogramì„ ì´ìš©í•œ ì‹œê°í™”\n",
        "from scipy.cluster.hierarchy import ward, dendrogram\n",
        "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
        "fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
        "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=titles);\n",
        "plt.tick_params(\\\n",
        "    axis= 'x',          # changes apply to the x-axis\n",
        "    which='both',      # both major and minor ticks are affected\n",
        "    bottom='off',      # ticks along the bottom edge are off\n",
        "    top='off',         # ticks along the top edge are off\n",
        "    labelbottom='off')\n",
        "plt.tight_layout() #show plot with tight layout"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E_1nJZfwl9Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [\"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.23.PNG\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 2)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Gl2eOJAArw0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}